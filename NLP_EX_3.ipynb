{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyOKrf8/BdQ+uQgFoVNgmczb",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Saakshi23/ALL-THE-EXPERIMENT/blob/main/NLP_EX_3.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import nltk\n",
        "from nltk.corpus import stopwords\n",
        "from nltk.tokenize import word_tokenize\n",
        "\n",
        "# Download NLTK stopwords data if not already downloaded\n",
        "#nltk.download('stopwords')\n",
        "#nltk.download('punkt')\n",
        "\n",
        "def remove_stopwords(input_text):\n",
        "    # Tokenize the input text into words\n",
        "    words = word_tokenize(input_text)\n",
        "\n",
        "    # Get the English stopwords from NLTK\n",
        "    stop_words = set(stopwords.words('english'))\n",
        "\n",
        "    # Remove stopwords from the tokenized words\n",
        "    filtered_words = [word for word in words if word.lower() not in stop_words]\n",
        "\n",
        "    # Join the filtered words to form the output text\n",
        "    output_text = ' '.join(filtered_words)\n",
        "\n",
        "    return output_text\n",
        "\n",
        "# Creating a longer sentence with 80 words\n",
        "user_input = (\"The provided Python code demonstrates stopword removal using the Natural Language Toolkit (NLTK) library.\"\n",
        "              \"In the first step, the sample sentence, which reads “This is a sample sentence, \"\n",
        "              \"showing off the stop words filtration,” is tokenized into words using the word_tokenize function. \"\n",
        "              \"The code then filters out stopwords by converting each word to lowercase and checking its presence in the set of English stopwords obtained\"\n",
        "              \" from NLTK. The resulting filtered_sentence is printed, showcasing both lowercased and original versions, \"\n",
        "              \"providing a cleaned version of the sentence with common English stopwords removed.\")\n",
        "\n",
        "# 1. Removal of stop words and separating them with commas\n",
        "output_commas = remove_stopwords(user_input)\n",
        "output_commas = ', '.join(output_commas.split())\n",
        "\n",
        "# 2. Removal of stop words and separating them with slashes (/)\n",
        "output_slashes = remove_stopwords(user_input)\n",
        "output_slashes = '/'.join(output_slashes.split())\n",
        "\n",
        "# 3. Calculate the number of words before and after removing stopping words\n",
        "original_word_count = len(word_tokenize(user_input))\n",
        "filtered_word_count = len(word_tokenize(remove_stopwords(user_input)))\n",
        "\n",
        "print(\"Original Text:\\n\", user_input)\n",
        "print(\"\\n1. Text after removing stopwords and separating with commas:\\n\", output_commas)\n",
        "print(\"\\n2. Text after removing stopwords and separating with slashes:\\n\", output_slashes)\n",
        "print(\"\\n3. Number of words before removing stopwords:\", original_word_count)\n",
        "print(\"   Number of words after removing stopwords:\", filtered_word_count)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TGGR5-ZtR_q3",
        "outputId": "6991dce4-1ee2-4f89-cd52-ba4c7e12f7cc"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Original Text:\n",
            " The provided Python code demonstrates stopword removal using the Natural Language Toolkit (NLTK) library.In the first step, the sample sentence, which reads “This is a sample sentence, showing off the stop words filtration,” is tokenized into words using the word_tokenize function. The code then filters out stopwords by converting each word to lowercase and checking its presence in the set of English stopwords obtained from NLTK. The resulting filtered_sentence is printed, showcasing both lowercased and original versions, providing a cleaned version of the sentence with common English stopwords removed.\n",
            "\n",
            "1. Text after removing stopwords and separating with commas:\n",
            " provided, Python, code, demonstrates, stopword, removal, using, Natural, Language, Toolkit, (, NLTK, ), library.In, first, step, ,, sample, sentence, ,, reads, “, sample, sentence, ,, showing, stop, words, filtration, ,, ”, tokenized, words, using, word_tokenize, function, ., code, filters, stopwords, converting, word, lowercase, checking, presence, set, English, stopwords, obtained, NLTK, ., resulting, filtered_sentence, printed, ,, showcasing, lowercased, original, versions, ,, providing, cleaned, version, sentence, common, English, stopwords, removed, .\n",
            "\n",
            "2. Text after removing stopwords and separating with slashes:\n",
            " provided/Python/code/demonstrates/stopword/removal/using/Natural/Language/Toolkit/(/NLTK/)/library.In/first/step/,/sample/sentence/,/reads/“/sample/sentence/,/showing/stop/words/filtration/,/”/tokenized/words/using/word_tokenize/function/./code/filters/stopwords/converting/word/lowercase/checking/presence/set/English/stopwords/obtained/NLTK/./resulting/filtered_sentence/printed/,/showcasing/lowercased/original/versions/,/providing/cleaned/version/sentence/common/English/stopwords/removed/.\n",
            "\n",
            "3. Number of words before removing stopwords: 102\n",
            "   Number of words after removing stopwords: 69\n"
          ]
        }
      ]
    }
  ]
}