{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyN2ktZtA11ckPfaMaGcvRSH",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Saakshi23/ALL-THE-EXPERIMENT/blob/main/NLP_EX_2.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aWOoLHmEUdxX",
        "outputId": "d9b35376-6442-4707-bbea-f66ea7a515e3"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Original Text:  Certainly! Stemming and lemmatization are text normalization techniques used in natural language processing \n",
            "\n",
            "Stemmed Words:  ['certainli', '!', 'stem', 'and', 'lemmat', 'are', 'text', 'normal', 'techniqu', 'use', 'in', 'natur', 'languag', 'process']\n",
            "Lemmatized Words:  ['Certainly', '!', 'Stemming', 'and', 'lemmatization', 'are', 'text', 'normalization', 'technique', 'used', 'in', 'natural', 'language', 'processing']\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Package punkt is already up-to-date!\n",
            "[nltk_data] Downloading package wordnet to /root/nltk_data...\n",
            "[nltk_data]   Package wordnet is already up-to-date!\n"
          ]
        }
      ],
      "source": [
        "from nltk.stem import PorterStemmer, WordNetLemmatizer\n",
        "from nltk.tokenize import word_tokenize\n",
        "import nltk\n",
        "nltk.download('punkt')\n",
        "nltk.download('wordnet')\n",
        "\n",
        "text = \"Certainly! Stemming and lemmatization are text normalization techniques used in natural language processing \"\n",
        "\"to reduce words to their base or root form.\"\n",
        "\"I'll provide examples for both stemming and lemmatization in Python using NLTK (Natural Language Toolkit) library..\"\n",
        "\n",
        "words = word_tokenize(text)\n",
        "\n",
        "stemmer = PorterStemmer()\n",
        "stemmed_words = [stemmer.stem(word) for word in words]\n",
        "\n",
        "lemmatizer = WordNetLemmatizer()\n",
        "lemmatized_words = [lemmatizer.lemmatize(word) for word in words]\n",
        "\n",
        "print(\"Original Text: \", text)\n",
        "print(\"\\nStemmed Words: \", stemmed_words)\n",
        "print(\"Lemmatized Words: \", lemmatized_words)\n"
      ]
    }
  ]
}